{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dj2a3l747hSG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "# import ipdb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Helper functions for loading images.\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)\n",
    "\n",
    "# flag for whether you're training or not\n",
    "is_train = True\n",
    "is_key_frame = True # TODO: set this to false to train on the video frames, instead of the key frames\n",
    "model_to_load = 'model_video.ckpt' # This is the model to load during testing, if you want to eval a previously-trained model.\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "# Parameters for data loader\n",
    "params = {'batch_size': 32,  # TODO: fill in the batch size. often, these are things like 32,64,128,or 256\n",
    "          'shuffle': True,\n",
    "          'num_workers': 2 \n",
    "          }\n",
    "batchsize = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0001\n",
    "# NOTE: depending on your optimizer, you may want to tune other hyperparameters as well\n",
    "\n",
    "# Datasets\n",
    "# TODO: put the path to your train, test, validation txt files\n",
    "if is_key_frame:\n",
    "    label_file_train =  ''\n",
    "    label_file_val  =  ''\n",
    "\n",
    "else:\n",
    "    label_file_train = ''\n",
    "    label_file_val = ''\n",
    "    label_file_test = ''\n",
    "\n",
    "# You should normalize based on the average image in the training set. This shows \n",
    "# an example of doing normalization\n",
    "mean = #todo\n",
    "std = #todo\n",
    "# If you want to pad or resize your images, you can put the parameters for that below.\n",
    "\n",
    "# Generators\n",
    "# NOTE: if you don't want to pad or resize your images, you should delete the Pad and Resize\n",
    "# transforms from all three _dataset definitions.\n",
    "train_dataset = Mds189(label_file_train,loader=default_loader,transform=transforms.Compose([\n",
    "#                                                transforms.Pad(requires_parameters),    # TODO: if you want to pad your images\n",
    "#                                                transforms.Resize(requires_parameters), # TODO: if you want to resize your images\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize(mean, std)\n",
    "                                           ]))\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, **params)\n",
    "\n",
    "val_dataset = Mds189(label_file_val,loader=default_loader,transform=transforms.Compose([\n",
    "#                                                transforms.Pad(),\n",
    "#                                                transforms.Resize(),\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize(mean, std)\n",
    "                                           ]))\n",
    "val_loader = data.DataLoader(val_dataset, **params)\n",
    "\n",
    "if not is_key_frame:\n",
    "    test_dataset = Mds189(label_file_test,loader=default_loader,transform=transforms.Compose([\n",
    "#                                                    transforms.Pad(),\n",
    "#                                                    transforms.Resize(),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize(mean, std)\n",
    "                                               ]))\n",
    "    test_loader = data.DataLoader(test_dataset, **params)\n",
    "\n",
    "# NOTE: you should not overwrite the models you try whose performance you're keeping track of.\n",
    "#       one thing you could do is have many different model forward passes in class NeuralNet()\n",
    "#       and then depending on which model you want to train/evaluate, you call that model's\n",
    "#       forward pass. this strategy will save you a lot of time in the long run. the last thing\n",
    "#       you want to do is have to recode the layer structure for a model (whose performance\n",
    "#       you're reporting) because you forgot to e.g., compute the confusion matrix on its results\n",
    "#       or visualize the error modes of your (best) model\n",
    "\n",
    "model = models.inception_v3(pretrained=True)\n",
    "# if we're only testing, we don't want to train for any epochs, and we want to load a model\n",
    "if not is_train:\n",
    "    num_epochs = 0\n",
    "    # model.load_state_dict(torch.load('model_video.ckpt'))\n",
    "# model.load_state_dict(torch.load('model_video2.ckpt'))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda() #TODO: define your loss here. hint: should just require calling a built-in pytorch layer.\n",
    "# NOTE: you can use a different optimizer besides Adam, like RMSProp or SGD, if you'd like\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "# Loop over epochs\n",
    "val_loss_list_epoch = []\n",
    "train_loss_list_step = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_groundtruth_list = []\n",
    "prev_val_acc = 0\n",
    "predicted = None\n",
    "validation_count = 0\n",
    "\n",
    "print('Beginning training..')\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    print('epoch {}'.format(epoch))\n",
    "    loss_list = []\n",
    "    \n",
    "    for i, (local_batch,local_labels) in enumerate(train_loader):\n",
    "        # Transfer to GPU\n",
    "        local_ims, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model.forward(local_ims)\n",
    "        loss = criterion(outputs, local_labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "      \n",
    "        # NOTE: if you use Google Colab's tensorboard-like feature to visualize\n",
    "        #       the loss, you do not need to plot it here. just take a screenshot\n",
    "        #       of the loss curve and include it in your write-up.\n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_total = local_labels.size(0)\n",
    "        train_correct = (predicted == local_labels).sum().item()\n",
    "        train_loss_list_step.append(train_correct*100/train_total)\n",
    "\n",
    "        if (i+1) % 4 == 0:\n",
    "            print('training accuracy: ' + str(train_correct*100/train_total))\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))  \n",
    "            \n",
    "        print('training accuracy: ' + str(train_correct*100/train_total))\n",
    "        \n",
    "\n",
    "            \n",
    "    val_correct = 0\n",
    "    val_total = 0 \n",
    "    predicted_list = []\n",
    "    val_groundtruth_list = []\n",
    "    loss_sum = 0\n",
    "    for (val_batch,val_labels) in val_loader:\n",
    "        # Transfer to GPU\n",
    "        val_ims, val_labels = val_batch.to(device), val_labels.to(device)\n",
    "        val_outputs = model.forward(val_ims)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        predicted_list.extend(val_predicted)\n",
    "\n",
    "        val_total += val_labels.size(0)\n",
    "        val_groundtruth_list.extend(val_labels)\n",
    "        val_correct += (val_predicted == val_labels).sum().item()\n",
    "        loss = criterion(val_outputs, val_labels)\n",
    "        loss_sum += (loss.item())\n",
    "        \n",
    "    \n",
    "    val_acc = val_correct*100/val_total\n",
    "    val_loss_list.append(loss_sum)\n",
    "    print (\"Epoch validation accuracy: \" + str(val_acc))\n",
    "    val_loss_list_epoch.append(val_acc)\n",
    "    \n",
    "    if (val_acc <= prev_val_acc):\n",
    "      validation_count += 1\n",
    "      if validation_count >= 5:\n",
    "        print (\"Early termination\")\n",
    "        break;\n",
    "    else:\n",
    "      validation_count = 0\n",
    "        \n",
    "    prev_val_acc = val_acc\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print('Time: {}'.format(end - start))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neuron types NN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
